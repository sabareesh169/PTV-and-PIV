## Defining the structure of neural network and intitializing network parameters.
vel_layers = [3, 100, 100, 100, 100, 100, 100, 3]
vel_weights, vel_biases = initialize_NN(vel_layers)

## Charecteristic scales
c_l=0.05
c_t=0.001
c_v=c_l/c_t

## Load data
train_data=pd.read_csv("foc_train_data.csv")
test_data=pd.read_csv("foc_val_data.csv")
train_data = train_data
train_data = train_data.values
test_data = test_data.values

## Training data
initial = train_data[:,[0,1]].astype(np.float32)
initial_x_data = tf.constant(initial[:, 0][:, None], name='x_init', dtype=tf.float32)
initial_y_data = tf.constant(initial[:, 1][:, None], name='y_init', dtype=tf.float32)

final = train_data[:,[2,3]].astype(np.float32)
final_x_data = tf.constant(final[:, 0][:, None], name='x_final', dtype=tf.float32)
final_y_data = tf.constant(final[:, 1][:, None], name='y_final', dtype=tf.float32)

t_initial_data = tf.constant(train_data[:,6].astype(np.float32)[:, None], name='t_init')
t_final_data = tf.constant(train_data[:,7].astype(np.float32)[:, None], name='t_final')

## Training data in charescteristic length scales
initial_x_data_ch = tf.constant(initial[:, 0][:, None], name='x_init_ch', dtype=tf.float32)/c_l
initial_y_data_ch = tf.constant(initial[:, 1][:, None], name='y_init_ch', dtype=tf.float32)/c_l
initial_ch = tf.concat([initial_x_data, initial_y_data], 1)/c_l 

final_x_data_ch = tf.constant(final[:, 0][:, None], name='x_final_ch', dtype=tf.float32)/c_l
final_y_data_ch = tf.constant(final[:, 1][:, None], name='y_final_ch', dtype=tf.float32)/c_l
final_ch = tf.concat([final_x_data, final_y_data], 1)/c_l 

t_initial_data_ch = tf.constant(train_data[:,6].astype(np.float32)[:, None], name='t_init_ch')/c_t
t_final_data_ch = tf.constant(train_data[:,7].astype(np.float32)[:, None], name='t_final_ch')/c_t

## Testing data
test_initial = test_data[:,[0,1]].astype(np.float32)
test_initial_x_data = tf.constant(test_initial[:, 0][:, None], name='test_x_init', dtype=tf.float32)
test_initial_y_data = tf.constant(test_initial[:, 1][:, None], name='test_y_init', dtype=tf.float32)

test_final = test_data[:,[2,3]].astype(np.float32)
test_final_x_data = tf.constant(test_final[:, 0][:, None], name='x_final', dtype=tf.float32)
test_final_y_data = tf.constant(test_final[:, 1][:, None], name='y_final', dtype=tf.float32)

test_t_initial_data = tf.constant(test_data[:,6].astype(np.float32)[:, None], name='t_init')
test_t_final_data = tf.constant(test_data[:,7].astype(np.float32)[:, None], name='t_final')

## Testing data in charescteristic length scales
test_initial_x_data_ch = tf.constant(test_initial[:, 0][:, None], name='test_x_init_ch', dtype=tf.float32)/c_l
test_initial_y_data_ch = tf.constant(test_initial[:, 1][:, None], name='test_y_init_ch', dtype=tf.float32)/c_l
test_initial_ch = tf.concat([test_initial_x_data_ch, test_initial_y_data_ch], 1)

test_final_x_data_ch = tf.constant(test_final[:, 0][:, None], name='x_final_ch', dtype=tf.float32)/c_l
test_final_y_data_ch = tf.constant(test_final[:, 1][:, None], name='y_final_ch', dtype=tf.float32)/c_l
test_final_ch = tf.concat([test_final_x_data_ch, test_final_y_data_ch], 1)

test_t_initial_data_ch = tf.constant(test_data[:,6].astype(np.float32)[:, None], name='t_init_ch')/c_t
test_t_final_data_ch = tf.constant(test_data[:,7].astype(np.float32)[:, None], name='t_final_ch')/c_t


## Selecting the final points within a radius for each initial particle.
tree=spatial.KDTree(initial)
list_=tree.query_ball_point(initial, 0.1)

## Velocity for the train and test particles
vel_pred = neural_net(t_initial_data_ch, initial_x_data_ch, initial_y_data_ch, vel_weights, vel_biases)
test_vel_pred = neural_net(test_t_initial_data_ch, test_initial_x_data_ch, test_initial_y_data_ch, vel_weights, vel_biases)

with tf.Session() as sess:
    true_vel_x_ch = sess.run((final_x_data_ch - initial_x_data_ch)/(t_final_data_ch - t_initial_data_ch))
    true_vel_y_ch = sess.run((final_y_data_ch - initial_y_data_ch)/(t_final_data_ch - t_initial_data_ch))
    true_vel_ch = np.concatenate([true_vel_x_ch, true_vel_y_ch], axis=1)
    vel_placeholder = tf.placeholder(tf.float32, shape=(initial.shape[0], 2))
    loss_vel = tf.reduce_sum(tf.square(vel_pred[:,:2] - vel_placeholder))
    loss_NS_x, loss_NS_y, loss_cont = NS(vel_weights, vel_biases, lb, ub)
    phy_loss = loss_NS_x + loss_NS_y + loss_cont
    alpha = tf.constant(0.001, dtype=tf.float32)
    beta = tf.constant(1., dtype=tf.float32)
    sigma = tf.Variable(1., dtype=tf.float32)
    likelihood = tf.placeholder(dtype=tf.float32)
    neg_log_prob = (2*alpha+102)*tf.log(sigma)+(beta+likelihood/2)/sigma**2
    optimizer_ph = tf.train.AdamOptimizer().minimize(phy_loss, global_step=global_step, var_list=vel_weights+vel_biases)
    optimizer_vel = tf.train.AdamOptimizer().minimize(loss_vel, global_step=global_step, var_list=vel_weights+vel_biases)
    optimzer_sigma = tf.train.AdamOptimizer().minimize(neg_log_prob, global_step=global_step, var_list=sigma)
    init = tf.global_variables_initializer()
    sess.run(init)
    k=0
